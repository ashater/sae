{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80de081b-1dbe-480d-ae09-1db120402007",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a4856ac-0155-43aa-bdee-bab3dd7ec4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from nnsight import LanguageModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the language model with specific parameters\n",
    "model = LanguageModel(\"google/gemma-2b-it\", trust_remote_code=True, device_map=\"cuda:1\", low_cpu_mem_usage=True, torch_dtype=torch.float16)\n",
    "model.requires_grad_(False)\n",
    "\n",
    "\n",
    "\n",
    "from sae_lens import SAE\n",
    "layer = 12\n",
    "\n",
    "# get the SAE for this layer\n",
    "sae, cfg_dict, _ = SAE.from_pretrained(\n",
    "    release = \"gemma-2b-res-jb\",\n",
    "    sae_id = f\"blocks.{layer}.hook_resid_post\",\n",
    "    device = 'cuda:1'\n",
    ")\n",
    "# # Load the SAE weights using safetensors\n",
    "# from safetensors import safe_open\n",
    "# with safe_open(\"/home/ashater/work/sae.safetensors\", framework=\"pt\") as st:\n",
    "#     w_dec = st.get_tensor(\"W_dec\").to('cuda:1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b8c1793-102b-40fa-ac95-1bed54ade0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#torch.cuda.is_available()\n",
    "\n",
    "#torch.cuda.device_count()\n",
    "#len(docs)\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.current_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "76b70c13-046f-4a20-b9a0-1cf02d0c55a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' search'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.decode(model.tokenizer.encode(prompt)[-10])\n",
    "#sae.W_dec == w_dec\n",
    "\n",
    "#cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "#cos(w_dec[471,:], sae.W_dec).topk(100).indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e041f35-f593-43db-b018-5a1f7a0849e8",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f5b3826-4114-49b1-b353-f8c927c1a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Self-explanation in 18 lines\n",
    "# feature = 471  #@param {type: \"integer\"}\n",
    "feature = 9210 # google\n",
    "#feature = 5892  #@param {type: \"integer\"}\n",
    "# feature = 9415\n",
    "# feature = 3629    \n",
    "# scale = 55.5 #@param {type: \"number\"}\n",
    "scale = 17.7 #@param {type: \"number\"}\n",
    "se_demo = True  #@param {type: \"boolean\"}\n",
    "max_new_tokens = 200  #@param {type: \"integer\"}\n",
    "n_generate = 1  #@param {type: \"integer\"}\n",
    "vals = ['positive', 'neutral', 'negative']\n",
    "samples = pd.read_excel('/home/ashater/work/sae/sentence_sentiment_gpt4o.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd931463-c743-4604-9c09-58d19613c67a",
   "metadata": {},
   "source": [
    "## Main code prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7fe05b2d-753a-4144-9bde-a698208668ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      " Which search engine is the best?<start_of_turn>model\n",
      "  |'**Google** is widely considered the **best search engine** in the world. It has a massive index of over 1 trillion web pages, and its algorithms are constantly updated to provide accurate and relevant results.\\n\\n**Other top search engines include:**\\n\\n* **Microsoft Bing**\\n* **Yandex**\\n* **Baidu**\\n* **DuckDuckGo**\\n* **Ecosia**\\n\\n**Factors to consider when choosing a search engine:**\\n\\n* **Accuracy:** The ability of the engine to find exact matches.\\n* **Relevance:** The quality and freshness of the results.\\n* **Speed:** How quickly the results are displayed.\\n* **Privacy:** The security and data protection practices of the company.\\n* **Features:** The additional tools and services offered by the engine.\\n\\n**Ultimately, the best search engine for you depends on your individual needs and preferences.** Consider trying out different engines to find one that best suits your needs.'|<built-in method indices of Tensor object at 0x7f837b8a3fb0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt = \"\"\"<start_of_turn>user\\n Which search engine is the best?<start_of_turn>model\\n  \"\"\"\n",
    "\n",
    "\n",
    "#prompt = '<start_of_turn>user\\nWhat is the meaning of the word \"X\"?<end_of_turn>\\n<start_of_turn>model\\nThe meaning of the word \"X\" is \"'\n",
    "\n",
    "# prompt = '<start_of_turn>user\\n' + ismpl +  '<end_of_turn>\\n<start_of_turn>model X'\n",
    "positions = [i for i, a in enumerate(model.tokenizer.encode(prompt)) if model.tokenizer.decode([a]) == \"X\"]\n",
    "with model.generate(prompt, max_new_tokens=max_new_tokens, num_return_sequences=n_generate, do_sample=False, temperature=0, top_k=1, scan=False, validate=False) as gen:\n",
    "    # vector steering section\n",
    "    # for feature_i in topics:\n",
    "    vector = sae.W_dec[[feature]]\n",
    "    vector = vector / vector.norm()\n",
    "    vector = vector * scale \n",
    "    # setting vector into layer 2\n",
    "    #for position in positions:\n",
    "    model.model.layers[2].output[0][:, -10] = vector # we steer token search\n",
    "        \n",
    "    # get final output saved\n",
    "    out = model.generator.output.save()\n",
    "    # capture at layer 6 or 12\n",
    "    resid = model.model.layers[12].output.save()\n",
    "    \n",
    "features = sae.encode(resid[0])\n",
    "summed_activations = features.abs().sum(dim=1) # Sort by max activations\n",
    "summed_activations = features\n",
    "# top_activations_indices = summed_activations.topk(200).indices # Get indices of top 20    \n",
    "top_activations_indices = summed_activations.indices # Get indices of top 20    \n",
    "\n",
    "\n",
    "for i, l in enumerate(model.tokenizer.batch_decode(out)):\n",
    "    s = repr(l.partition(prompt)[2].partition(\"<eos>\")[0])\n",
    "    print(prompt + \"|\"+ s + \"|\" + str(top_activations_indices))\n",
    "    # print(str(top_activations_indices))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563adb23-1bad-420f-962b-2e5fb101700d",
   "metadata": {},
   "source": [
    "## summed activations across tokens, finance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "185d1d1a-ca6f-46f6-8b3f-317d91738580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8731, 10841,  5233,  3048,  1645, 11597,  6099,  7650,  6802,  8618,\n",
       "         2227,  8297, 14175, 15051,  7254,  9210,  9653, 13000,  4662,  3831,\n",
       "         4029,  3958,  8824, 15140,  4395, 13944,  3208,  5067, 15178,  1910,\n",
       "        15689,  4930, 14206, 13336,  6020,   475,  7066, 11460,  1112, 15260,\n",
       "         8309, 14865, 10673,  4836, 11371, 15302,  5053, 10211,   787,   317,\n",
       "           78, 12146,  2059, 14395,  5942,  6646,   194,  9039, 11679, 10648,\n",
       "        12005,  2932, 11428,  5557,  7118,  8658,  3246,  7029, 13972,  6059,\n",
       "        12286, 11088,  6992,  9483, 14665,   310,  9914, 15927,  3875,  7092,\n",
       "         2625,  2029,  8611,  4641,  8281,  3565, 10029,  7737, 10685,  8960,\n",
       "        14621,  4640,  7651, 13912, 15086,  8728, 13203,  7279,  4223,  1149],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summed_activations[summed_activations > 10].shape\n",
    "idc = summed_activations.topk(100).indices\n",
    "\n",
    "#9210 in idc[0][0] # Google feature\n",
    "\n",
    "#6799 in idc # webbrowser feature\n",
    "#9210 in idc\n",
    "idc[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44780ee2-ad48-49d9-ae88-3d54c7063007",
   "metadata": {},
   "source": [
    "### Here turn off steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1ff69ec1-18d1-444d-af76-5c3431266dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      " Which search engine is the best?<start_of_turn>model\n",
      "  |'**The best search engine is subjective and depends on individual preferences and needs.** There is no single \"best\" option for everyone.\\n\\n**Here are some of the most popular and highly rated search engines:**\\n\\n* **Google:**\\n    * Large and comprehensive index of websites and content.\\n    * Advanced search features, including natural language processing and machine learning.\\n    * Popular and widely used, with a vast network of links and resources.\\n* **Bing:**\\n    * Microsoft\\'s search engine, known for its accuracy and relevance.\\n    * Focus on semantic search, understanding the meaning of your query.\\n    * Includes Microsoft Office products and services.\\n* **Yandex:**\\n    * Popular in Europe and Asia, with a strong focus on local and regional information.\\n    * Advanced search features and a comprehensive directory of websites.\\n    * Offers a translation function for language support.\\n* **Baidu:**\\n    * The most widely used search engine'|<built-in method indices of Tensor object at 0x7f837b8a3170>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt = \"\"\"<start_of_turn>user\\n Which search engine is the best?<start_of_turn>model\\n  \"\"\"\n",
    "\n",
    "\n",
    "#prompt = '<start_of_turn>user\\nWhat is the meaning of the word \"X\"?<end_of_turn>\\n<start_of_turn>model\\nThe meaning of the word \"X\" is \"'\n",
    "\n",
    "# prompt = '<start_of_turn>user\\n' + ismpl +  '<end_of_turn>\\n<start_of_turn>model X'\n",
    "positions = [i for i, a in enumerate(model.tokenizer.encode(prompt)) if model.tokenizer.decode([a]) == \"X\"]\n",
    "with model.generate(prompt, max_new_tokens=max_new_tokens, num_return_sequences=n_generate, do_sample=False, temperature=0, top_k=1, scan=False, validate=False) as gen:\n",
    "   \n",
    "    # get final output saved\n",
    "    out = model.generator.output.save()\n",
    "    # capture at layer 6 or 12\n",
    "    resid = model.model.layers[12].output.save()\n",
    "    \n",
    "features = sae.encode(resid[0])\n",
    "summed_activations = features.abs().sum(dim=1) # Sort by max activations\n",
    "summed_activations = features\n",
    "# top_activations_indices = summed_activations.topk(200).indices # Get indices of top 20    \n",
    "top_activations_indices = summed_activations.indices # Get indices of top 20    \n",
    "\n",
    "\n",
    "for i, l in enumerate(model.tokenizer.batch_decode(out)):\n",
    "    s = repr(l.partition(prompt)[2].partition(\"<eos>\")[0])\n",
    "    print(prompt + \"|\"+ s + \"|\" + str(top_activations_indices))\n",
    "    # print(str(top_activations_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "270272f8-35cd-4d21-91c4-0ccd2dcd9288",
   "metadata": {},
   "outputs": [],
   "source": [
    "idc_ns = summed_activations.topk(100).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8a673437-dd22-427b-a5a9-41af52c39733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   10,    11,    12,    13,    14,    15,    16,    17,    18,\n",
       "          19,    20,    21,    22,    23,    24,    25,    26,    27,\n",
       "          28,    29,    30,    31,    32,    33,    34,    35,    36,\n",
       "          37,    38,    39,    40,    41,    42,    43,    44,    45,\n",
       "          46,    47,    75,   795,  1258,  2411,  2667,  2728,  2870,\n",
       "        3561,  3685,  3962,  4027,  4376,  4388,  4401,  4402,  4723,\n",
       "        4975,  5639,  6564,  6642,  6754,  6755,  7446,  7479,  7493,\n",
       "        7977,  8183,  8473,  9002,  9198,  9388, 10109, 10298, 10323,\n",
       "       10833, 11700, 11707, 12159, 12480, 13064, 13399, 13852, 14956,\n",
       "       15615, 15760, 15968, 16252])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56fd0cb-ce1c-4c91-b2ed-5e5a9e5ceed9",
   "metadata": {},
   "source": [
    "## Now we re-run inference with prompt as it was returned from first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3e021bf2-12e9-4eef-a4b0-f9df8df765aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      "'**The best search engine is subjective and depends on individual preferences and needs.** There is no single \"best\" option for everyone.\\n\\n**Here are some of the most popular and highly rated search engines:**\\n\\n* **Google:**\\n    * Large and comprehensive index of websites and content.\\n    * Advanced search features, including natural language processing and machine learning.\\n    * Popular and widely used, with a vast network of links and resources.\\n* **Bing:**\\n    * Microsoft\\'s search engine, known for its accuracy and relevance.\\n    * Focus on semantic search, understanding the meaning of your query.\\n    * Includes Microsoft Office products and services.\\n* **Yandex:**\\n    * Popular in Europe and Asia, with a strong focus on local and regional information.\\n    * Advanced search features and a comprehensive directory of websites.\\n    * Offers a translation function for language support.\\n* **Baidu:**\\n    * The most widely used search engine'<start_of_turn>model\n",
      "  |'**The passage highlights the subjectivity of search engines and emphasizes that no single option is best for everyone.**\\n\\n**Key Points:**\\n\\n* Search engines are personal and depend on individual preferences and needs.\\n* Popular search engines like Google, Bing, andYandex offer varying features and results.\\n* Search engines employ different methodologies, including indexing, natural language processing, and semantic search.\\n* The choice of search engine can have significant impact on the search result.\\n\\n**Additional Insights:**\\n\\n* The passage suggests that individuals may have specific preferences for certain factors such as query speed, accuracy, or convenience.\\n* The popularity of search engines is often driven by factors such as brand recognition, user base, and advertising revenue.\\n* The passage acknowledges the importance of user experience and the subjective nature of search engine evaluation.'|<built-in method indices of Tensor object at 0x7f83b1de9f70>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"\"\"<start_of_turn>user\\n\"\"\" + s + \"\"\"<start_of_turn>model\\n  \"\"\"\n",
    "\n",
    "\n",
    "positions = [i for i, a in enumerate(model.tokenizer.encode(prompt)) if model.tokenizer.decode([a]) == \"X\"]\n",
    "with model.generate(prompt, max_new_tokens=max_new_tokens, num_return_sequences=n_generate, do_sample=True, scan=False, validate=False) as gen:\n",
    "    # get final output saved\n",
    "    out = model.generator.output.save()\n",
    "    # capture at layer 6 or 12\n",
    "    resid = model.model.layers[12].output.save()\n",
    "    \n",
    "features = sae.encode(resid[0])\n",
    "summed_activations = features.abs().sum(dim=1) # Sort by max activations\n",
    "summed_activations = features\n",
    "# top_activations_indices = summed_activations.topk(200).indices # Get indices of top 20    \n",
    "top_activations_indices = summed_activations.indices # Get indices of top 20    \n",
    "\n",
    "\n",
    "for i, l in enumerate(model.tokenizer.batch_decode(out)):\n",
    "    s = repr(l.partition(prompt)[2].partition(\"<eos>\")[0])\n",
    "    print(prompt + \"|\"+ s + \"|\" + str(top_activations_indices))\n",
    "    # print(str(top_activations_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "74de56a3-91d1-4759-bb31-f67c62c33513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15314,  9987, 16269, 14829,  9366, 12171,  6045,  4595,  3093, 10137,\n",
       "         3139, 15313,  7378,  3412,  2652,  5043,  5363,   310, 14603, 16008,\n",
       "         6626,  4361,  2132, 14115,  8602,  6571,  2086,  4594,  7059, 10963,\n",
       "         5092,  2862,  1293, 11618,  2443,  7737,  7384,  7461,  2160, 13294,\n",
       "          778,  8960, 12939, 10635, 14358, 14621, 11327,   712, 13018,  5498,\n",
       "        16363, 14665,  8263,  7747, 11679,  4247,  5365,  9410, 13352, 12855,\n",
       "         2763, 15086, 11396,  7118,  9039,  7733, 11597,  5053,  1516,  8807,\n",
       "          200,  3455, 15695,  2270, 12498, 15689, 13944,  3246, 14395,   967,\n",
       "         3522,  8824, 11460, 14206, 10420, 10731,  3766,  3958,  9358,  7254,\n",
       "         7385,  9653,  3831,   563, 15051,  4662,  1910,  4406, 13000,  8297],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idc2 = summed_activations.topk(100).indices\n",
    "49 in idc2 # webbrowser feature\n",
    "#idc2.shape\n",
    "\n",
    "idc2[0][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e75bfe1b-bfb6-433c-8cfb-0158c2be84b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.setdiff1d(idc2[0][9].cpu(), idc3[0][9].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6eef7b2f-6f3d-484b-966b-19a24835c12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4487, 14845, 15314,  9987,  6067,  9366,  5541, 10323, 10841,  6578,\n",
       "         2125,  6099,  6754,  5943, 11597,   535,  6973, 11363,  2310,  2589,\n",
       "         2345,  3583,  9388, 10298, 13950, 16115,  8109,  7905, 11912, 13932,\n",
       "         8871,  1293, 11679,  9591,  8731,  6626,  5363,  2652,  8639, 15051,\n",
       "         5233,  7652,  6571,  5092,   310,  8960,  9653,  7378, 13944, 15689,\n",
       "         3412,  4594,  2066, 14621, 14115,  7384,  1910, 16363, 13018,  3958,\n",
       "         4247,  7737,  2086, 14175,  5053, 14206, 11460,  8900, 11618,  8263,\n",
       "        14665,  7696,  2227,  7118,  7059,  2132,  4361, 14395,  5043,  8602,\n",
       "         2862,  6802,  3048,  2892, 10963, 13000,  3246,  9039,  4662,  9210,\n",
       "        13132, 15086,  2160,  8618, 12939,  3831, 14358,  8824,  2255,  7912],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idc3 = summed_activations.topk(100).indices\n",
    "\n",
    "\n",
    "idc3[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "68775103-a997-45ef-ba41-f704db20940f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 106, 1645, 108, 7702, 603, 132801, 106765, 235248]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " [a for i, a in enumerate(model.tokenizer.encode(prompt))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062e7340-b8d7-4972-96c3-c09df308a69e",
   "metadata": {},
   "source": [
    "## Get features for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d4f51d09-59c6-4838-b25e-442a4295dffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, False, False, False, False, False, True, False, False, False]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idc = summed_activations.mean(dim=1).topk(5000).indices\n",
    "[g in idc for g in [354, 2105, 4218, 5239, 6545, 7529, 8461, 11614, 11916, 14291, 15399]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
