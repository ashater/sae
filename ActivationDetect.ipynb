{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80de081b-1dbe-480d-ae09-1db120402007",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a4856ac-0155-43aa-bdee-bab3dd7ec4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from nnsight import LanguageModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the language model with specific parameters\n",
    "model = LanguageModel(\"google/gemma-2b-it\", trust_remote_code=True, device_map=\"cuda:0\", low_cpu_mem_usage=True, torch_dtype=torch.float16)\n",
    "model.requires_grad_(False)\n",
    "\n",
    "\n",
    "\n",
    "from sae_lens import SAE\n",
    "layer = 6\n",
    "\n",
    "# get the SAE for this layer\n",
    "sae, cfg_dict, _ = SAE.from_pretrained(\n",
    "    release = \"gemma-2b-res-jb\",\n",
    "    sae_id = f\"blocks.{layer}.hook_resid_post\",\n",
    "    device = 'cuda:0'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e041f35-f593-43db-b018-5a1f7a0849e8",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f5b3826-4114-49b1-b353-f8c927c1a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Self-explanation in 18 lines\n",
    "feature = 471  #@param {type: \"integer\"}\n",
    "#feature = 5892  #@param {type: \"integer\"}\n",
    "# feature = 9415\n",
    "scale = 76  #@param {type: \"number\"}\n",
    "se_demo = True  #@param {type: \"boolean\"}\n",
    "max_new_tokens = 80  #@param {type: \"integer\"}\n",
    "n_generate = 1  #@param {type: \"integer\"}\n",
    "vals = ['positive', 'neutral', 'negative']\n",
    "samples = pd.read_excel('/home/ashater/work/sae/sentence_sentiment_gpt4o.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd931463-c743-4604-9c09-58d19613c67a",
   "metadata": {},
   "source": [
    "## Main code prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ba60abf-6920-4e9c-ac4e-bf0cdca06b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "v = [\"How does does financial sentiment affect credit rating, particular related to stock price?\", \"what is IBM credit rating and how does  it effect lending?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7fe05b2d-753a-4144-9bde-a698208668ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      "What is the meaning of the word \"X\"?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "The meaning of the word \"X\" is \"|'a measure of the creditworthiness and strength of a person, organization, or country\". It is often used to indicate the probability of a borrower or issuer fulfilling their financial obligations.'|tensor([[  471, 11912, 10771,  3390,  1213, 15881,  5347,  2157, 16334,   556,\n",
      "         11785, 15299, 12670,  1630,  5490,  3586,  1587, 12630,  5624,  5396]],\n",
      "       device='cuda:0')\n",
      "<start_of_turn>user\n",
      "What is the meaning of the word \"X\"?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "The meaning of the word \"X\" is \"|'a measure of the creditworthiness, financial standing, or operating capacity of an entity\". It is often used by investors, creditors, and other parties who make decisions based on this information.\\n\\nIn a financial context, a credit rating is a numerical rating given to a company or other entity by a major credit rating agency, such as Moody\\'s Investors Service or Standard & Poor\\'s. The credit'|tensor([[  471, 11912, 10771,  3390,  1213, 15881,  5347,  2157, 16334,   556,\n",
      "         11785, 15299, 12670,  1630,  5490,  3586,  1587, 12630,  5624,  5396]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "full_res = []\n",
    "#v = range(0,10)\n",
    "for ismpl in v:\n",
    "\n",
    "\n",
    "    # prompt = \"\"\"<start_of_turn>user\\nCan you rate  the following sentnece as a financial credit sentiment, very positive, \n",
    "    # somewhat positive, neutral, somewhat negative, \n",
    "    # very negative? \"\"\" + samples.iloc[ismpl].Sentence + '<end_of_turn>\\n<start_of_turn>model\\nThe sentiment of the setence is \"X\"'\n",
    "\n",
    "    prompt = '<start_of_turn>user\\nWhat is the meaning of the word \"X\"?<end_of_turn>\\n<start_of_turn>model\\nThe meaning of the word \"X\" is \"'\n",
    "\n",
    "    # prompt = '<start_of_turn>user\\n' + ismpl +  '<end_of_turn>\\n<start_of_turn>model X'\n",
    "    positions = [i for i, a in enumerate(model.tokenizer.encode(prompt)) if model.tokenizer.decode([a]) == \"X\"]\n",
    "    with model.generate(prompt, max_new_tokens=max_new_tokens, num_return_sequences=n_generate, do_sample=True, scan=False, validate=False) as gen:\n",
    "        # vector steering section\n",
    "        vector = sae.W_dec[[feature]]\n",
    "        vector = vector / vector.norm()\n",
    "        vector = vector * scale\n",
    "        # setting vector into layer 2\n",
    "        for position in positions:\n",
    "          model.model.layers[2].output[0][:, position] = vector\n",
    "            \n",
    "        # get final output saved\n",
    "        out = model.generator.output.save()\n",
    "        # capture at layer 6 or 12\n",
    "        resid = model.model.layers[12].output.save()\n",
    "        \n",
    "    features = sae.encode(resid[0])\n",
    "    summed_activations = features.abs().sum(dim=1) # Sort by max activations\n",
    "    top_activations_indices = summed_activations.topk(20).indices # Get indices of top 20    \n",
    "\n",
    "    for i, l in enumerate(model.tokenizer.batch_decode(out)):\n",
    "        s = repr(l.partition(prompt)[2].partition(\"<eos>\")[0])\n",
    "        print(prompt + \"|\"+ s + \"|\" + str(top_activations_indices))\n",
    "        # print(str(top_activations_indices))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563adb23-1bad-420f-962b-2e5fb101700d",
   "metadata": {},
   "source": [
    "## summed activations across tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "185d1d1a-ca6f-46f6-8b3f-317d91738580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16384])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_activations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062e7340-b8d7-4972-96c3-c09df308a69e",
   "metadata": {},
   "source": [
    "## Get features for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4f51d09-59c6-4838-b25e-442a4295dffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21, 16384])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
