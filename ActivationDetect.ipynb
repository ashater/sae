{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80de081b-1dbe-480d-ae09-1db120402007",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a4856ac-0155-43aa-bdee-bab3dd7ec4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from nnsight import LanguageModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the language model with specific parameters\n",
    "model = LanguageModel(\"google/gemma-2b-it\", trust_remote_code=True, device_map=\"cuda:1\", low_cpu_mem_usage=True, torch_dtype=torch.float16)\n",
    "model.requires_grad_(False)\n",
    "\n",
    "\n",
    "\n",
    "from sae_lens import SAE\n",
    "layer = 12\n",
    "\n",
    "# get the SAE for this layer\n",
    "sae, cfg_dict, _ = SAE.from_pretrained(\n",
    "    release = \"gemma-2b-res-jb\",\n",
    "    sae_id = f\"blocks.{layer}.hook_resid_post\",\n",
    "    device = 'cuda:1'\n",
    ")\n",
    "# Load the SAE weights using safetensors\n",
    "from safetensors import safe_open\n",
    "with safe_open(\"/home/ashater/work/sae.safetensors\", framework=\"pt\") as st:\n",
    "    w_dec = st.get_tensor(\"W_dec\").to('cuda:1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b8c1793-102b-40fa-ac95-1bed54ade0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#torch.cuda.is_available()\n",
    "\n",
    "#torch.cuda.device_count()\n",
    "#len(docs)\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.current_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76b70c13-046f-4a20-b9a0-1cf02d0c55a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3629,   475,  6443,   787, 14794,  5972,  5503, 15488,  4383,  4722,\n",
       "         8050,  4991,  7091, 12567,  1729,  8691, 12185, 16042, 13945, 13265,\n",
       "        11450,  5611,  9251, 14709,  6738,  5659,  9041,  8431,  8211, 14557,\n",
       "        11135,  6775,  1687,  8728, 10550,  9459,  6943, 14992,  9952, 15132,\n",
       "         1004, 13303, 15616,  8370, 13180, 15194, 12101, 10275,   889, 14433,\n",
       "        11472,  9166,  1254,  1276, 12955, 10202, 13693,  7128,  9954, 12760,\n",
       "         1977,  4701, 10394, 10754,  7344,  8475, 15455,  1913,  2356,  5581,\n",
       "         3519,   172, 12890, 13044,  9313, 11299, 10402, 10261,  5454,  6346,\n",
       "         5624,  2969,  9894,  9198,  1568, 10725,  9632,  4256,    92, 15403,\n",
       "         2624, 14645,  3363,  1053,  1419,  1258, 15607, 15804,   923, 15685],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sae.W_dec == w_dec\n",
    "\n",
    "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "cos(w_dec[471,:], sae.W_dec).topk(100).indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e041f35-f593-43db-b018-5a1f7a0849e8",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f5b3826-4114-49b1-b353-f8c927c1a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Self-explanation in 18 lines\n",
    "feature = 471  #@param {type: \"integer\"}\n",
    "#feature = 5892  #@param {type: \"integer\"}\n",
    "# feature = 9415\n",
    "# feature = 3629    \n",
    "scale = 55.5 #@param {type: \"number\"}\n",
    "se_demo = True  #@param {type: \"boolean\"}\n",
    "max_new_tokens = 200  #@param {type: \"integer\"}\n",
    "n_generate = 1  #@param {type: \"integer\"}\n",
    "vals = ['positive', 'neutral', 'negative']\n",
    "samples = pd.read_excel('/home/ashater/work/sae/sentence_sentiment_gpt4o.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd931463-c743-4604-9c09-58d19613c67a",
   "metadata": {},
   "source": [
    "## Main code prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7fe05b2d-753a-4144-9bde-a698208668ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      " The president anounced new tariffs but at the same time promised tax cuts.<end_of_turn>\n",
      "<start_of_turn>model\n",
      " \n",
      "    How would that affect the economy of the country? |\"\\n\\nThe president's announcement of new tariffs would likely lead to a decrease in imports, as businesses would be less likely to purchase goods from abroad if they become more expensive. This would have a ripple effect on the economy, as it would lead to a decrease in demand for other goods and services, which would in turn lead to a decrease in employment and production.\\n\\nOn the other hand, the promise of tax cuts would likely lead to an increase in spending, as consumers would be more likely to buy goods and services if they are more affordable. This would lead to a boost in the economy, as it would increase demand for goods and services. \\n\\nOverall, the impact of the president's announcement would be complex and depends on a number of factors, including the specific details of the tariffs and tax cuts, the state of the economy, and the political environment.\"|<built-in method indices of Tensor object at 0x7fca47093950>\n"
     ]
    }
   ],
   "source": [
    "full_res = []\n",
    "#v = range(0,10)\n",
    "for ismpl in v:\n",
    "\n",
    "\n",
    "    # prompt = \"\"\"<start_of_turn>user\\nCan you rate  the following sentnece as a financial credit sentiment, very positive, \n",
    "    # somewhat positive, neutral, somewhat negative, \n",
    "    # very negative? \"\"\" + ismpl + '<end_of_turn>\\n<start_of_turn>model\\nThe sentiment of the setence is \"X\"'\n",
    "\n",
    "\n",
    "    prompt = \"\"\"<start_of_turn>user\\n The president anounced new tariffs but at the same time promised tax cuts.<end_of_turn>\\n<start_of_turn>model\\n \n",
    "    How would that affect the economy of the country? \"\"\"\n",
    "\n",
    "    \n",
    "    #prompt = '<start_of_turn>user\\nWhat is the meaning of the word \"X\"?<end_of_turn>\\n<start_of_turn>model\\nThe meaning of the word \"X\" is \"'\n",
    "\n",
    "    # prompt = '<start_of_turn>user\\n' + ismpl +  '<end_of_turn>\\n<start_of_turn>model X'\n",
    "    positions = [i for i, a in enumerate(model.tokenizer.encode(prompt)) if model.tokenizer.decode([a]) == \"X\"]\n",
    "    with model.generate(prompt, max_new_tokens=max_new_tokens, num_return_sequences=n_generate, do_sample=True, scan=False, validate=False) as gen:\n",
    "        # vector steering section\n",
    "        # for feature_i in topics:\n",
    "        vector = sae.W_dec[[feature]]\n",
    "        vector = vector / vector.norm()\n",
    "        vector = vector * scale\n",
    "        # setting vector into layer 2\n",
    "        # for position in positions:\n",
    "        #   model.model.layers[2].output[0][:, position] = vector\n",
    "            \n",
    "        # get final output saved\n",
    "        out = model.generator.output.save()\n",
    "        # capture at layer 6 or 12\n",
    "        resid = model.model.layers[12].output.save()\n",
    "        \n",
    "    features = sae.encode(resid[0])\n",
    "    summed_activations = features.abs().sum(dim=1) # Sort by max activations\n",
    "    summed_activations = features\n",
    "    # top_activations_indices = summed_activations.topk(200).indices # Get indices of top 20    \n",
    "    top_activations_indices = summed_activations.indices # Get indices of top 20    \n",
    "\n",
    "    \n",
    "    for i, l in enumerate(model.tokenizer.batch_decode(out)):\n",
    "        s = repr(l.partition(prompt)[2].partition(\"<eos>\")[0])\n",
    "        print(prompt + \"|\"+ s + \"|\" + str(top_activations_indices))\n",
    "        # print(str(top_activations_indices))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563adb23-1bad-420f-962b-2e5fb101700d",
   "metadata": {},
   "source": [
    "## summed activations across tokens, finance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "185d1d1a-ca6f-46f6-8b3f-317d91738580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False, False, False, False, False, False, False, False, False]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summed_activations[summed_activations > 10].shape\n",
    "idc = summed_activations.topk(1000).indices\n",
    "[g in idc for g in [354, 2105, 4218, 5239, 6545, 7529, 8461, 11614, 11916, 14291, 15399]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062e7340-b8d7-4972-96c3-c09df308a69e",
   "metadata": {},
   "source": [
    "## Get features for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d4f51d09-59c6-4838-b25e-442a4295dffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.9184, 1.9771, 0.0000,  ..., 3.8246, 0.0000, 2.4047],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "       device='cuda:1', grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_activations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
